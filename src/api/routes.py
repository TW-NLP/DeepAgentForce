"""
REST API è·¯ç”± - å®Œæ•´ç‰ˆ
åŒ…å«ï¼šå¯¹è¯æ¥å£ + GraphRAG çŸ¥è¯†åº“æ¥å£ + é…ç½®ç®¡ç†æ¥å£

è·¯å¾„: src/api/routes.py
"""

import logging
import uuid
import shutil
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Optional, Dict, List
from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks
from pydantic import BaseModel
import json
from config.settings import settings
from src.workflow.agent import ConversationalAgent

# GraphRAG å¯¼å…¥
try:
    from src.services.rag_graph import GraphRAGPipeline
    GRAPHRAG_AVAILABLE = True
except ImportError:
    GRAPHRAG_AVAILABLE = False
    logging.warning("GraphRAG æ¨¡å—æœªæ‰¾åˆ°ï¼Œç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨")

logger = logging.getLogger(__name__)

# åˆ›å»ºè·¯ç”±
router = APIRouter()

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = Path("config/saved_config.json")
CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
HISTORY_FILE = Path("config/saved_history.json")


class SavedHistoryResponse(BaseModel):
    success: bool
    history: List[Dict[str, Any]]

# ==================== æ•°æ®æ¨¡å‹ï¼ˆå¯¹è¯ï¼‰ ====================

class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    message: str
    session_id: Optional[str] = None


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”"""
    message: str
    session_id: str
    timestamp: str


class HistoryResponse(BaseModel):
    """å†å²è®°å½•å“åº”"""
    history: List[Dict[str, str]]
    session_id: str


class StatusResponse(BaseModel):
    """çŠ¶æ€å“åº”"""
    status: str
    message: str


# ==================== æ•°æ®æ¨¡å‹ï¼ˆGraphRAGï¼‰ ====================

class DocumentMetadata(BaseModel):
    """æ–‡æ¡£å…ƒæ•°æ®"""
    title: Optional[str] = None
    author: Optional[str] = None
    category: Optional[str] = None
    tags: Optional[List[str]] = None


class UploadResponse(BaseModel):
    """ä¸Šä¼ å“åº”"""
    success: bool
    message: str
    document_id: str
    document_name: str
    chunks_count: int
    uploaded_at: str


class DeleteResponse(BaseModel):
    """åˆ é™¤å“åº”"""
    success: bool
    message: str
    document_id: str


class QueryRequest(BaseModel):
    """æŸ¥è¯¢è¯·æ±‚"""
    question: str
    top_k_communities: Optional[int] = 10


class QueryResponse(BaseModel):
    """æŸ¥è¯¢å“åº”"""
    success: bool
    question: str
    answer: str
    processing_time: float


class DocumentInfo(BaseModel):
    """æ–‡æ¡£ä¿¡æ¯"""
    document_id: str
    name: str
    path: str
    chunks: int
    uploaded_at: str
    metadata: Dict


class ListDocumentsResponse(BaseModel):
    """æ–‡æ¡£åˆ—è¡¨å“åº”"""
    success: bool
    total: int
    documents: List[DocumentInfo]


class IndexStatusResponse(BaseModel):
    """ç´¢å¼•çŠ¶æ€å“åº”"""
    success: bool
    is_indexed: bool
    total_documents: int
    total_entities: int
    total_relationships: int
    total_communities: int
    message: str


# ==================== æ•°æ®æ¨¡å‹ï¼ˆé…ç½®ï¼‰ ====================

class ConfigResponse(BaseModel):
    """é…ç½®å“åº”"""
    success: bool
    message: str
    config: Optional[Dict[str, str]] = None


# ==================== Session ç®¡ç†å™¨ ====================

class SessionManager:
    """Session ç®¡ç†å™¨"""
    
    def __init__(self):
        self.sessions: Dict[str, ConversationalAgent] = {}
        self.session_timestamps: Dict[str, datetime] = {}
    
    def get_or_create_session(self, session_id: Optional[str] = None) -> tuple[str, ConversationalAgent]:
        """è·å–æˆ–åˆ›å»º Session"""
        if session_id and session_id in self.sessions:
            self.session_timestamps[session_id] = datetime.now()
            return session_id, self.sessions[session_id]
        
        new_session_id = str(uuid.uuid4())
        self.sessions[new_session_id] = ConversationalAgent()
        self.session_timestamps[new_session_id] = datetime.now()
        
        logger.info(f"åˆ›å»ºæ–°ä¼šè¯: {new_session_id}")
        return new_session_id, self.sessions[new_session_id]
    
    def clear_session(self, session_id: str):
        """æ¸…ç©º Session å†å²"""
        if session_id in self.sessions:
            self.sessions[session_id].clear_history()
            logger.info(f"æ¸…ç©ºä¼šè¯å†å²: {session_id}")
    
    def delete_session(self, session_id: str):
        """åˆ é™¤ Session"""
        if session_id in self.sessions:
            del self.sessions[session_id]
            del self.session_timestamps[session_id]
            logger.info(f"åˆ é™¤ä¼šè¯: {session_id}")
    
    def cleanup_old_sessions(self, timeout_seconds: int = 3600):
        """æ¸…ç†è¿‡æœŸ Session"""
        now = datetime.now()
        expired_sessions = [
            sid for sid, ts in self.session_timestamps.items()
            if (now - ts).total_seconds() > timeout_seconds
        ]
        
        for sid in expired_sessions:
            self.delete_session(sid)
        
        if expired_sessions:
            logger.info(f"æ¸…ç†äº† {len(expired_sessions)} ä¸ªè¿‡æœŸä¼šè¯")
    
    def get_session_count(self) -> int:
        """è·å–å½“å‰ Session æ•°é‡"""
        return len(self.sessions)


# ==================== GraphRAG ç®¡ç†å™¨ ====================

class GraphRAGManager:
    """GraphRAG çŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self):
        self.pipeline: Optional[GraphRAGPipeline] = None
        self.initialized = False
        self.upload_dir = Path("./uploads")
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        
        if GRAPHRAG_AVAILABLE:
            self._initialize_pipeline()
    
    def _initialize_pipeline(self):
        """åˆå§‹åŒ– GraphRAG Pipeline"""
        try:
            self.pipeline = GraphRAGPipeline(
                llm_api_key=getattr(settings, 'LLM_API_KEY'),
                embedding_api_key=getattr(settings, 'EMBEDDING_API_KEY'),
                llm_url=getattr(settings, 'LLM_URL'),
                embedding_url=getattr(settings, 'EMBEDDING_URL'),
                embedding_name=getattr(settings, 'EMBEDDING_MODEL'),
                embedding_dim=getattr(settings, 'EMBEDDING_DIM', 1024),
                llm_name=getattr(settings, 'LLM_MODEL'),
                storage_dir=getattr(settings, 'GRAPHRAG_STORAGE_DIR', './graphrag_storage')
            )
            
            try:
                self.pipeline.load("default")
                logger.info("âœ… GraphRAG: åŠ è½½å·²æœ‰çŸ¥è¯†åº“")
            except FileNotFoundError:
                logger.info("ğŸ“ GraphRAG: åˆ›å»ºæ–°çŸ¥è¯†åº“")
            
            self.initialized = True
            logger.info("âœ… GraphRAG Pipeline åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ GraphRAG åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            self.initialized = False
    
    def is_ready(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å°±ç»ª"""
        return self.initialized and self.pipeline is not None
    
    def save_upload_file(self, upload_file: UploadFile) -> Path:
        """ä¿å­˜ä¸Šä¼ æ–‡ä»¶"""
        file_path = self.upload_dir / f"{uuid.uuid4()}_{upload_file.filename}"
        
        try:
            with file_path.open("wb") as buffer:
                shutil.copyfileobj(upload_file.file, buffer)
            return file_path
        finally:
            upload_file.file.close()
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.is_ready():
            return {
                'enabled': False,
                'total_documents': 0,
                'total_entities': 0,
                'total_relationships': 0,
                'total_communities': 0,
                'index_status': 'Not initialized'
            }
        
        total_communities = sum(len(comms) for comms in self.pipeline.communities.values())
        is_indexed = self.pipeline.community_summary_index is not None
        
        return {
            'enabled': True,
            'total_documents': len(self.pipeline.documents),
            'total_entities': len(self.pipeline.entities),
            'total_relationships': len(self.pipeline.relationships),
            'total_communities': total_communities,
            'index_status': 'Indexed' if is_indexed else 'Not indexed'
        }
    
    def save(self):
        """ä¿å­˜çŸ¥è¯†åº“"""
        if self.is_ready():
            try:
                self.pipeline.save("default")
                logger.info("âœ… GraphRAG çŸ¥è¯†åº“å·²ä¿å­˜")
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜çŸ¥è¯†åº“å¤±è´¥: {e}")


# å…¨å±€ç®¡ç†å™¨å®ä¾‹
session_manager = SessionManager()
graphrag_manager = GraphRAGManager()


# ==================== è¾…åŠ©å‡½æ•° ====================


def load_history_from_file() -> List[Dict[str, Any]]:
    if HISTORY_FILE.exists():
        try:
            with HISTORY_FILE.open('r', encoding='utf-8') as f:
                data = json.load(f)
                # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨æ ¼å¼
                if isinstance(data, list):
                    return data
                return []
        except Exception as e:
            logger.error(f"âŒ è¯»å–å†å²è®°å½•å¤±è´¥: {e}")
            return []
    return []

def check_graphrag_ready():
    """æ£€æŸ¥ GraphRAG æ˜¯å¦å°±ç»ª"""
    if not GRAPHRAG_AVAILABLE:
        raise HTTPException(
            status_code=503,
            detail="GraphRAG æ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…"
        )
    
    if not graphrag_manager.is_ready():
        raise HTTPException(
            status_code=503,
            detail="GraphRAG æœåŠ¡æœªå°±ç»ª"
        )


async def rebuild_index_background():
    """åå°ä»»åŠ¡ï¼šé‡å»ºç´¢å¼•"""
    try:
        logger.info("ğŸ“Š å¼€å§‹é‡å»º GraphRAG ç´¢å¼•...")
        graphrag_manager.pipeline.rebuild_index()
        graphrag_manager.save()
        logger.info("âœ… GraphRAG ç´¢å¼•é‡å»ºå®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ é‡å»ºç´¢å¼•å¤±è´¥: {e}", exc_info=True)


def load_config_from_file() -> Dict[str, Any]:
    """
    ä»æ–‡ä»¶åŠ è½½é…ç½® (ä¿®å¤ç‰ˆï¼šæ”¯æŒè¯»å– JSON ç»“æ„)
    è¿”å›åµŒå¥—å­—å…¸ç»“æ„ï¼Œä¾‹å¦‚: {'llm_config': {'LLM_API_KEY': '...'}, ...}
    """
    config_data = {
        "llm_config": {},
        "search_config": {},
        "firecrawl_config": {},
        "embedding_config": {}
    }
    
    # 1. å°è¯•ä» JSON æ–‡ä»¶åŠ è½½
    if CONFIG_FILE.exists():
        try:
            with CONFIG_FILE.open('r', encoding='utf-8') as f:
                saved_data = json.load(f)
                # åˆå¹¶ä¿å­˜çš„æ•°æ®
                for group, values in saved_data.items():
                    if group in config_data:
                        config_data[group].update(values)
            logger.info(f"âœ… ä»æ–‡ä»¶åŠ è½½é…ç½®æˆåŠŸ")
        except json.JSONDecodeError:
            logger.warning("âš ï¸ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    # 2. (å¯é€‰) ä»ç¯å¢ƒå˜é‡è¡¥å……/è¦†ç›–å…³é”®é…ç½®
    # å¦‚æœä½ æƒ³è®©ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§æœ€é«˜ï¼Œå¯ä»¥åœ¨è¿™é‡Œé€šè¿‡ os.getenv è¦†ç›– config_data
    # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œä»…å½“æ–‡ä»¶ä¸å­˜åœ¨å¯¹åº”å€¼æ—¶æ‰è¯»å–ç¯å¢ƒå˜é‡
    env_mapping = {
        'LLM_API_KEY': ('llm_config', 'LLM_API_KEY'),
        'LLM_URL': ('llm_config', 'LLM_URL'),
        'LLM_MODEL': ('llm_config', 'LLM_MODEL'),
        'TAVILY_API_KEY': ('search_config', 'TAVILY_API_KEY'),
        'FIRECRAWL_API_KEY': ('firecrawl_config', 'FIRECRAWL_API_KEY'),
        'FIRECRAWL_URL': ('firecrawl_config', 'FIRECRAWL_URL'),
        'EMBEDDING_API_KEY': ('embedding_config', 'EMBEDDING_API_KEY'),
        'EMBEDDING_URL': ('embedding_config', 'EMBEDDING_URL'),
        'EMBEDDING_MODEL': ('embedding_config', 'EMBEDDING_MODEL'),
    }

    for env_key, (group, dict_key) in env_mapping.items():
        if dict_key not in config_data[group] or not config_data[group][dict_key]:
            env_val = os.getenv(env_key)
            if env_val:
                config_data[group][dict_key] = env_val

    return config_data


def save_config_to_file(config: Dict[str, str]):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    try:
        config_dict={"llm_config":{}, "search_config":{}, "firecrawl_config":{}, "embedding_config":{}}
        
        # LLM é…ç½®
        for key in ['LLM_API_KEY', 'LLM_URL', 'LLM_MODEL']:
            if key in config:
                config_dict['llm_config'][key]=config[key]
        
        
        # æœç´¢é…ç½®
        if 'TAVILY_API_KEY' in config:
            config_dict['search_config']['TAVILY_API_KEY'] = config['TAVILY_API_KEY']
        
        # Firecrawl é…ç½®
        for key in ['FIRECRAWL_API_KEY', 'FIRECRAWL_URL']:
            if key in config:
                config_dict['firecrawl_config'][key]=config[key]


        # Embedding é…ç½®
        for key in ['EMBEDDING_API_KEY', 'EMBEDDING_URL', 'EMBEDDING_MODEL']:
            if key in config:
                config_dict['embedding_config'][key]=config[key]
        # ä¿å­˜jsonæ ¼å¼
        with CONFIG_FILE.open('w', encoding='utf-8') as f:
            json.dump(config_dict, f, ensure_ascii=False, indent=4)
        
        logger.info(f"âœ… é…ç½®å·²ä¿å­˜åˆ°æ–‡ä»¶: {CONFIG_FILE}")

        return config_dict
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        raise
def save_conversation_to_file(user_msg: str, ai_msg: str):
    """å°†å¯¹è¯è¿½åŠ ä¿å­˜åˆ° JSON æ–‡ä»¶"""
    try:
        # 1. è¯»å–ç°æœ‰è®°å½•
        history_data = []
        if HISTORY_FILE.exists():
            with HISTORY_FILE.open('r', encoding='utf-8') as f:
                try:
                    history_data = json.load(f)
                    if not isinstance(history_data, list):
                        history_data = []
                except json.JSONDecodeError:
                    history_data = []

        # 2. è·å–æ—¶é—´
        timestamp = datetime.now().isoformat()

        # 3. è¿½åŠ æ–°è®°å½• (ä¿å­˜ä¸ºä¸€ç»„å¯¹è¯)
        # è¿™é‡Œæˆ‘ä»¬è®¾è®¡ç»“æ„ä¸ºï¼šä¸€æ¡è®°å½•åŒ…å« question å’Œ answer
        new_entry = {
            "id": str(uuid.uuid4()), # ç»™ä¸ªIDæ–¹ä¾¿å‰ç«¯ç´¢å¼•
            "timestamp": timestamp,
            "user_content": user_msg,
            "ai_content": ai_msg
        }
        history_data.append(new_entry)

        # 4. å†™å…¥æ–‡ä»¶
        with HISTORY_FILE.open('w', encoding='utf-8') as f:
            json.dump(history_data, f, ensure_ascii=False, indent=4)
            
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

# ==================== å¯¹è¯æ¥å£ ====================
@router.get("/history/saved", response_model=SavedHistoryResponse, tags=["å¯¹è¯"])
async def get_saved_history():
    """è·å– config/saved_history.json ä¸­çš„å†å²è®°å½•"""
    history_data = load_history_from_file()
    return SavedHistoryResponse(
        success=True,
        history=history_data
    )



@router.post("/chat", response_model=ChatResponse, tags=["å¯¹è¯"])
async def chat(request: ChatRequest):
    """åŒæ­¥å¯¹è¯æ¥å£"""
    try:
        session_manager.cleanup_old_sessions(settings.SESSION_TIMEOUT)
        session_id, agent = session_manager.get_or_create_session(request.session_id)
        
        logger.info(f"[{session_id}] æ”¶åˆ°æ¶ˆæ¯: {request.message[:50]}...")
        
        # 1. è·å– AI å›å¤
        response_content = await agent.chat(request.message)
        
        # 2. â˜…â˜…â˜… æ–°å¢ï¼šä¿å­˜åˆ° saved_history.json â˜…â˜…â˜…
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¿å­˜çš„æ˜¯è¿™ä¸€è½®çš„å¯¹è¯
        save_conversation_to_file(request.message, response_content)
        
        return ChatResponse(
            message=response_content,
            session_id=session_id,
            timestamp=datetime.now().isoformat()
        )
    
    except Exception as e:
        logger.error(f"å¯¹è¯å¤„ç†å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/history/{session_id}", response_model=HistoryResponse, tags=["å¯¹è¯"])
async def get_history(session_id: str):
    """è·å–å¯¹è¯å†å²"""
    if session_id not in session_manager.sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    agent = session_manager.sessions[session_id]
    
    return HistoryResponse(
        history=agent.get_history(),
        session_id=session_id
    )


@router.post("/clear/{session_id}", response_model=StatusResponse, tags=["å¯¹è¯"])
async def clear_history(session_id: str):
    """æ¸…ç©ºå¯¹è¯å†å²"""
    if session_id not in session_manager.sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session_manager.clear_session(session_id)
    
    return StatusResponse(
        status="ok",
        message="History cleared"
    )


@router.delete("/session/{session_id}", response_model=StatusResponse, tags=["å¯¹è¯"])
async def delete_session(session_id: str):
    """åˆ é™¤ Session"""
    if session_id not in session_manager.sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session_manager.delete_session(session_id)
    
    return StatusResponse(
        status="ok",
        message="Session deleted"
    )


# ==================== GraphRAG æ¥å£ï¼ˆçœç•¥éƒ¨åˆ†ä»£ç ä»¥ä¿æŒç®€æ´ï¼‰====================

@router.post("/graphrag/documents/upload", response_model=UploadResponse, tags=["GraphRAG"])
async def upload_document(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    title: Optional[str] = None,
    author: Optional[str] = None,
    category: Optional[str] = None,
    auto_rebuild: bool = True
):
    """ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
    check_graphrag_ready()
    
    allowed_extensions = {'.pdf', '.docx', '.doc', '.txt', '.md', '.markdown', '.csv'}
    file_extension = Path(file.filename).suffix.lower()
    
    if file_extension not in allowed_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}"
        )
    
    try:
        file_path = graphrag_manager.save_upload_file(file)
        logger.info(f"ğŸ“„ æ–‡ä»¶å·²ä¿å­˜: {file_path}")
        
        metadata = {
            "title": title or file.filename,
            "author": author,
            "category": category,
            "original_filename": file.filename,
            "file_extension": file_extension,
            "uploaded_at": datetime.now().isoformat()
        }
        
        doc_uuid = graphrag_manager.pipeline.add_document(str(file_path), metadata)
        doc_info = graphrag_manager.pipeline.documents[
            graphrag_manager.pipeline.uuid_to_docid[doc_uuid]
        ]
        
        if auto_rebuild:
            background_tasks.add_task(rebuild_index_background)
        
        return UploadResponse(
            success=True,
            message="æ–‡æ¡£ä¸Šä¼ æˆåŠŸ" + ("ï¼Œæ­£åœ¨åå°é‡å»ºç´¢å¼•" if auto_rebuild else ""),
            document_id=doc_uuid,
            document_name=file.filename,
            chunks_count=len(doc_info['chunks']),
            uploaded_at=doc_info['added_at']
        )
        
    except Exception as e:
        logger.error(f"âŒ ä¸Šä¼ æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
        if 'file_path' in locals() and file_path.exists():
            file_path.unlink()
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.get("/graphrag/documents", response_model=ListDocumentsResponse, tags=["GraphRAG"])
async def list_documents():
    """è·å–æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨"""
    check_graphrag_ready()
    
    try:
        docs = graphrag_manager.pipeline.list_documents()
        
        documents = [
            DocumentInfo(
                document_id=doc['uuid'],
                name=doc['name'],
                path=doc['path'],
                chunks=doc['chunks'],
                uploaded_at=doc['added_at'],
                metadata=doc['metadata']
            )
            for doc in docs
        ]
        
        return ListDocumentsResponse(
            success=True,
            total=len(documents),
            documents=documents
        )
        
    except Exception as e:
        logger.error(f"âŒ è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.post("/graphrag/index/rebuild", tags=["GraphRAG"])
async def rebuild_index(background_tasks: BackgroundTasks):
    """æ‰‹åŠ¨è§¦å‘ç´¢å¼•é‡å»º"""
    check_graphrag_ready()
    
    stats = graphrag_manager.get_stats()
    if stats['total_documents'] == 0:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰æ–‡æ¡£å¯ä»¥ç´¢å¼•")
    
    try:
        background_tasks.add_task(rebuild_index_background)
        
        return {
            "success": True,
            "message": "ç´¢å¼•é‡å»ºä»»åŠ¡å·²æ·»åŠ åˆ°åå°é˜Ÿåˆ—",
            "total_documents": stats['total_documents']
        }
        
    except Exception as e:
        logger.error(f"âŒ è§¦å‘ç´¢å¼•é‡å»ºå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è§¦å‘ç´¢å¼•é‡å»ºå¤±è´¥: {str(e)}")


# ==================== é…ç½®ç®¡ç†æ¥å£ ====================
class ConfigResponse(BaseModel):
    """é…ç½®å“åº”"""
    success: bool
    message: str
    # âš ï¸ å…³é”®ä¿®æ”¹ï¼šå¿…é¡»æ˜¯ Any æˆ–è€…æ˜¯ dictï¼Œå¦åˆ™ Pydantic ä¼šæ‹¦æˆªåµŒå¥— JSON æŠ¥é”™
    config: Optional[Dict[str, Any]] = None 

# ==================== è¾…åŠ©å‡½æ•°ï¼ˆé…ç½®ï¼‰ ====================

def load_config_from_file() -> Dict[str, Any]:
    """ä» JSON æ–‡ä»¶åŠ è½½é…ç½®ï¼ˆè¿”å›åµŒå¥—ç»“æ„ï¼‰"""
    if CONFIG_FILE.exists():
        try:
            with CONFIG_FILE.open('r', encoding='utf-8') as f:
                # ç›´æ¥è¯»å– JSON ç»“æ„
                return json.load(f)
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    # é»˜è®¤ç©ºç»“æ„ï¼Œé˜²æ­¢å‰ç«¯æŠ¥é”™
    return {
        "llm_config": {},
        "search_config": {},
        "firecrawl_config": {},
        "embedding_config": {}
    }

def save_config_to_file(new_flat_config: Dict[str, str]) -> Dict[str, Any]:
    """
    ä¿å­˜é…ç½®ï¼š
    1. å‰ç«¯ä¼ è¿‡æ¥çš„æ˜¯æ‰å¹³çš„ {'LLM_API_KEY': '...'}
    2. æˆ‘ä»¬è¦æŠŠå®ƒåˆå¹¶è¿›ç°æœ‰çš„åµŒå¥— JSON ç»“æ„ {'llm_config': {'LLM_API_KEY': ...}}
    """
    # 1. å…ˆè¯»å–æ—§çš„å®Œæ•´é…ç½®
    current_config = load_config_from_file()
    
    # 2. å®šä¹‰ å­—æ®µ -> ç»„ çš„æ˜ å°„å…³ç³» (å¿…é¡»ä¸å‰ç«¯ config.js ä¸€è‡´)
    field_mapping = {
        # LLM
        'LLM_API_KEY': 'llm_config', 
        'LLM_URL': 'llm_config', 
        'LLM_MODEL': 'llm_config',
        # Search
        'TAVILY_API_KEY': 'search_config',
        # Firecrawl
        'FIRECRAWL_API_KEY': 'firecrawl_config', 
        'FIRECRAWL_URL': 'firecrawl_config',
        # Embedding
        'EMBEDDING_API_KEY': 'embedding_config', 
        'EMBEDDING_URL': 'embedding_config', 
        'EMBEDDING_MODEL': 'embedding_config'
    }

    # 3. å°†æ‰å¹³çš„æ–°å€¼æ›´æ–°åˆ°åµŒå¥—ç»“æ„ä¸­
    for key, value in new_flat_config.items():
        # è·³è¿‡ç©ºå€¼
        if not value: 
            continue
            
        # è·³è¿‡æ²¡å˜çš„è„±æ•æ•°æ® (å¦‚æœå‰ç«¯ä¼ å›ï¼Œè¯´æ˜ç”¨æˆ·æ²¡æ”¹ï¼Œä¸è¦å­˜è¿›å»)
        if "..." in value and len(value) < 20:
            continue

        group = field_mapping.get(key)
        if group:
            if group not in current_config:
                current_config[group] = {}
            # æ›´æ–°å€¼
            current_config[group][key] = value

    # 4. å†™å…¥æ–‡ä»¶
    try:
        with CONFIG_FILE.open('w', encoding='utf-8') as f:
            json.dump(current_config, f, ensure_ascii=False, indent=4)
        logger.info(f"âœ… é…ç½®å·²ä¿å­˜åˆ°æ–‡ä»¶: {CONFIG_FILE}")
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        raise

    return current_config

# ==================== é…ç½®ç®¡ç†æ¥å£ ====================

@router.get("/config", response_model=ConfigResponse, tags=["é…ç½®ç®¡ç†"])
async def get_config():
    """è·å–å½“å‰é…ç½®ï¼ˆè¿”å›åµŒå¥—ç»“æ„ + è„±æ•ï¼‰"""
    try:
        # 1. è·å–åµŒå¥—å­—å…¸
        config_data = load_config_from_file()
        
        # 2. æ·±æ‹·è´ç”¨äºè„±æ•ï¼Œä¸ä¿®æ”¹åŸæ•°æ®
        safe_config = json.loads(json.dumps(config_data))
        
        # 3. éå†åµŒå¥—ç»“æ„è¿›è¡Œè„±æ•
        for group, items in safe_config.items():
            if isinstance(items, dict):
                for key, value in items.items():
                    # å¦‚æœåŒ…å« KEY ä¸”é•¿åº¦è¾ƒé•¿ï¼Œåˆ™è„±æ•
                    if value and isinstance(value, str) and 'KEY' in key.upper() and len(value) > 8:
                        items[key] = f"{value[:4]}...{value[-4:]}"
        
        # 4. è¿”å›
        return ConfigResponse(
            success=True,
            message="é…ç½®è·å–æˆåŠŸ",
            config=safe_config  # è¿™é‡Œæ˜¯åµŒå¥—å­—å…¸ï¼ŒConfigResponse ç°åœ¨å¯ä»¥æ¥æ”¶äº†
        )
        
    except Exception as e:
        logger.error(f"âŒ è·å–é…ç½®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–é…ç½®å¤±è´¥: {str(e)}")


@router.post("/config", response_model=ConfigResponse, tags=["é…ç½®ç®¡ç†"])
async def update_config(config: Dict[str, str]):
    """æ›´æ–°é…ç½®ï¼ˆæ¥æ”¶æ‰å¹³ç»“æ„ -> ä¿å­˜ä¸ºåµŒå¥—ç»“æ„ï¼‰"""
    try:
        # 1. ä¿å­˜é…ç½® (ä¼šå¤„ç†æ‰å¹³è½¬åµŒå¥—é€»è¾‘)
        # æ³¨æ„ï¼šè¿™é‡Œ config æ˜¯å‰ç«¯å‘æ¥çš„æ‰å¹³å­—å…¸ï¼Œsave_config_to_file ä¼šå¤„ç†å®ƒ
        updated_nested_config = save_config_to_file(config)
        
        # 2. æ›´æ–°å†…å­˜ä¸­çš„ settings (éœ€è¦å±•å¹³æ›´æ–°ï¼Œæˆ–è€…è®© settings æ”¯æŒè¯»å– dict)
        # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬æŠŠåµŒå¥—é…ç½®å±•å¹³åæ›´æ–°ç»™ settings
        flat_settings = {}
        for group in updated_nested_config.values():
            if isinstance(group, dict):
                flat_settings.update(group)
        settings.update(**flat_settings)
        
        logger.info(f"âœ… é…ç½®å·²æ›´æ–°å¹¶åº”ç”¨")
        
        return ConfigResponse(
            success=True,
            message="é…ç½®ä¿å­˜æˆåŠŸ",
            config=None # ä¿å­˜æˆåŠŸä¸éœ€è¦è¿”å› config
        )
        
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°é…ç½®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°é…ç½®å¤±è´¥: {str(e)}")


# ==================== æœåŠ¡ä¿¡æ¯æ¥å£ ====================

@router.get("/info", tags=["æœåŠ¡ä¿¡æ¯"])
async def get_info():
    """è·å–æœåŠ¡ä¿¡æ¯"""
    graphrag_stats = graphrag_manager.get_stats()
    
    return {
        "service": settings.APP_NAME,
        "version": settings.APP_VERSION,
        "features": {
            "streaming": True,
            "graphrag": graphrag_stats['enabled'],
            "config_management": True
        },
        "endpoints": {
            "http": {
                "chat": "/api/chat",
                "config_get": "/api/config",
                "config_update": "/api/config"
            }
        },
        "graphrag_status": graphrag_stats
    }


@router.get("/stats", tags=["æœåŠ¡ä¿¡æ¯"])
async def get_stats():
    """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    graphrag_stats = graphrag_manager.get_stats()
    
    return {
        "active_sessions": session_manager.get_session_count(),
        "graphrag": graphrag_stats,
        "config_loaded": CONFIG_FILE.exists(),
        "timestamp": datetime.now().isoformat()
    }



@router.get("/graphrag/index/status", response_model=IndexStatusResponse, tags=["GraphRAG"])
async def get_index_status():
    """è·å–ç´¢å¼•çŠ¶æ€"""
    check_graphrag_ready()
    
    try:
        stats = graphrag_manager.get_stats()
        is_indexed = stats['index_status'] == 'Indexed'
        
        return IndexStatusResponse(
            success=True,
            is_indexed=is_indexed,
            total_documents=stats['total_documents'],
            total_entities=stats['total_entities'],
            total_relationships=stats['total_relationships'],
            total_communities=stats['total_communities'],
            message=stats['index_status']
        )
        
    except Exception as e:
        logger.error(f"âŒ è·å–ç´¢å¼•çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–ç´¢å¼•çŠ¶æ€å¤±è´¥: {str(e)}")
@router.post("/graphrag/query", response_model=QueryResponse, tags=["GraphRAG"])
async def query_knowledge_base(request: QueryRequest):
    """
    æŸ¥è¯¢çŸ¥è¯†åº“
    
    - **question**: è¦æŸ¥è¯¢çš„é—®é¢˜
    - **top_k_communities**: æ£€ç´¢çš„ç¤¾åŒºæ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰
    """
    check_graphrag_ready()
    
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="é—®é¢˜ä¸èƒ½ä¸ºç©º")
    
    try:
        start_time = datetime.now()
        
        # æ‰§è¡ŒæŸ¥è¯¢
        answer = graphrag_manager.pipeline.global_query(
            request.question,
            top_k_communities=request.top_k_communities
        )
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        logger.info(f"âœ… æŸ¥è¯¢å®Œæˆ: {request.question[:50]}... (è€—æ—¶ {processing_time:.2f}s)")
        
        return QueryResponse(
            success=True,
            question=request.question,
            answer=answer,
            processing_time=processing_time
        )
        
    except RuntimeError as e:
        if "ç´¢å¼•æœªæ„å»º" in str(e):
            raise HTTPException(
                status_code=400,
                detail="ç´¢å¼•æœªæ„å»ºï¼Œè¯·å…ˆä¸Šä¼ æ–‡æ¡£å¹¶ç­‰å¾…ç´¢å¼•æ„å»ºå®Œæˆ"
            )
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")