"""
REST API è·¯ç”± - ä¼˜åŒ–ç‰ˆ
ä¼˜åŒ–è¦ç‚¹ï¼š
1. ç»Ÿä¸€ rag_pipeline ç®¡ç†ï¼Œé¿å…é‡å¤åˆ›å»º
2. settings å˜åŒ–æ—¶è‡ªåŠ¨é‡æ–°åˆå§‹åŒ–
3. å•ä¾‹æ¨¡å¼ç¡®ä¿å…¨å±€å”¯ä¸€å®ä¾‹

è·¯å¾„: src/api/routes.py
"""

import logging
import uuid
import shutil
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Optional, Dict, List
from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks
from pydantic import BaseModel
import json
from config.settings import settings
from src.services.person_like_service import UserPreferenceMining

# GraphRAG å¯¼å…¥
try:
    from src.services.rag_graph import GraphRAGPipeline
    GRAPHRAG_AVAILABLE = True
except ImportError:
    GRAPHRAG_AVAILABLE = False
    logging.warning("GraphRAG æ¨¡å—æœªæ‰¾åˆ°ï¼Œç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨")

from src.api.websocket import ConversationHistoryManager

logger = logging.getLogger(__name__)

# åˆ›å»ºè·¯ç”±
router = APIRouter()

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = Path("data/saved_config.json")
CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
HISTORY_FILE = Path("data/history")


# ==================== æ•°æ®æ¨¡å‹ ====================

class SavedSessionItem(BaseModel):
    session_id: str
    created_at: Optional[str] = None
    updated_at: Optional[str] = None
    conversation_count: int
    conversation: List[Dict[str, Any]]
    # âœ… æ–°å¢ title å­—æ®µï¼Œç”¨äºå‰ç«¯æ˜¾ç¤ºå¯¹è¯æ‘˜è¦
    title: Optional[str] = "æ–°å¯¹è¯"

class SavedHistoryListResponse(BaseModel):
    success: bool
    total: int
    sessions: List[SavedSessionItem]

class SavedSessionDetailResponse(BaseModel):
    success: bool
    session_id: str
    conversations: List[Dict[str, Any]]


class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None


class ChatResponse(BaseModel):
    message: str
    session_id: str
    timestamp: str


class HistoryResponse(BaseModel):
    history: List[Dict[str, str]]
    session_id: str



class StatusResponse(BaseModel):
    status: str
    message: str


class DocumentMetadata(BaseModel):
    title: Optional[str] = None
    author: Optional[str] = None
    category: Optional[str] = None
    tags: Optional[List[str]] = None


class UploadResponse(BaseModel):
    success: bool
    message: str
    document_id: str
    document_name: str
    chunks_count: int
    uploaded_at: str


class DeleteResponse(BaseModel):
    success: bool
    message: str
    document_id: str


class QueryRequest(BaseModel):
    question: str
    top_k_communities: Optional[int] = 10


class QueryResponse(BaseModel):
    success: bool
    question: str
    answer: str
    processing_time: float


class DocumentInfo(BaseModel):
    document_id: str
    name: str
    path: str
    chunks: int
    uploaded_at: str
    metadata: Dict


class ListDocumentsResponse(BaseModel):
    success: bool
    total: int
    documents: List[DocumentInfo]


class IndexStatusResponse(BaseModel):
    success: bool
    is_indexed: bool
    total_documents: int
    total_entities: int
    total_relationships: int
    total_communities: int
    message: str


class ConfigResponse(BaseModel):
    success: bool
    message: str
    config: Optional[Dict[str, Any]] = None



class SavedSessionItem(BaseModel):
    session_id: str
    created_at: Optional[str] = None
    updated_at: Optional[str] = None
    conversation_count: int





# ==================== GraphRAG ç®¡ç†å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰====================

class GraphRAGManager:
    """
    GraphRAG çŸ¥è¯†åº“ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    ä¼˜åŒ–è¦ç‚¹ï¼š
    1. ç»Ÿä¸€ç®¡ç† rag_pipeline å®ä¾‹
    2. é…ç½®å˜åŒ–æ—¶è‡ªåŠ¨é‡æ–°åˆå§‹åŒ–
    3. å»¶è¿ŸåŠ è½½ï¼Œåªåœ¨éœ€è¦æ—¶åˆå§‹åŒ–
    """
    
    _instance = None
    _pipeline: Optional[GraphRAGPipeline] = None
    _config_hash: Optional[str] = None  # ç”¨äºæ£€æµ‹é…ç½®å˜åŒ–
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        if self._initialized:
            return
            
        self.upload_dir = Path("./uploads")
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        self._initialized = True
        
        logger.info("ğŸ“¦ GraphRAGManager åˆå§‹åŒ–å®Œæˆ")
    
    def _get_config_hash(self) -> str:
        """è·å–å½“å‰é…ç½®çš„å“ˆå¸Œå€¼ï¼Œç”¨äºæ£€æµ‹é…ç½®å˜åŒ–"""
        config_str = f"{settings.LLM_API_KEY}|{settings.LLM_URL}|{settings.LLM_MODEL}|" \
                     f"{settings.EMBEDDING_API_KEY}|{settings.EMBEDDING_URL}|{settings.EMBEDDING_MODEL}|" \
                     f"{settings.EMBEDDING_DIM}|{settings.GRAPHRAG_STORAGE_DIR}"
        return str(hash(config_str))
    
    def _should_reinitialize(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–ï¼ˆé…ç½®æ˜¯å¦å˜åŒ–ï¼‰"""
        current_hash = self._get_config_hash()
        if self._config_hash != current_hash:
            logger.info("ğŸ”„ æ£€æµ‹åˆ°é…ç½®å˜åŒ–ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ– GraphRAG")
            return True
        return False
    
    def _initialize_pipeline(self, force: bool = False):
        """
        åˆå§‹åŒ– GraphRAG Pipeline
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
        """
        if not GRAPHRAG_AVAILABLE:
            logger.warning("âš ï¸ GraphRAG æ¨¡å—ä¸å¯ç”¨")
            return
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–
        if not force and self._pipeline is not None and not self._should_reinitialize():
            return
        
        try:
            logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– GraphRAG Pipeline...")
            
            # åˆ›å»ºæ–°çš„ pipeline å®ä¾‹
            self._pipeline = GraphRAGPipeline(
                llm_api_key=settings.LLM_API_KEY,
                embedding_api_key=settings.EMBEDDING_API_KEY,
                llm_url=settings.LLM_URL,
                embedding_url=settings.EMBEDDING_URL,
                embedding_name=settings.EMBEDDING_MODEL,
                embedding_dim=settings.EMBEDDING_DIM,
                llm_name=settings.LLM_MODEL,
                storage_dir=settings.GRAPHRAG_STORAGE_DIR
            )
            
            # å°è¯•åŠ è½½å·²æœ‰çŸ¥è¯†åº“
            try:
                self._pipeline.load("default")
                logger.info("âœ… GraphRAG: åŠ è½½å·²æœ‰çŸ¥è¯†åº“æˆåŠŸ")
            except FileNotFoundError:
                logger.info("ğŸ“ GraphRAG: åˆ›å»ºæ–°çŸ¥è¯†åº“")
            
            # æ›´æ–°é…ç½®å“ˆå¸Œ
            self._config_hash = self._get_config_hash()
            
            logger.info("âœ… GraphRAG Pipeline åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ GraphRAG Pipeline åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            self._pipeline = None
            raise
    
    def get_pipeline(self) -> GraphRAGPipeline:
        """
        è·å– Pipeline å®ä¾‹ï¼ˆæ‡’åŠ è½½ + é…ç½®æ£€æµ‹ï¼‰
        
        Returns:
            GraphRAGPipeline å®ä¾‹
            
        Raises:
            HTTPException: å¦‚æœ GraphRAG ä¸å¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥
        """
        if not GRAPHRAG_AVAILABLE:
            raise HTTPException(
                status_code=503,
                detail="GraphRAG æ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…"
            )
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ï¼ˆé‡æ–°ï¼‰åˆå§‹åŒ–
        if self._pipeline is None or self._should_reinitialize():
            self._initialize_pipeline()
        
        if self._pipeline is None:
            raise HTTPException(
                status_code=503,
                detail="GraphRAG æœåŠ¡æœªå°±ç»ªï¼Œè¯·æ£€æŸ¥é…ç½®"
            )
        
        return self._pipeline
    
    def force_reinitialize(self):
        """å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–ï¼ˆç”¨äºé…ç½®æ›´æ–°åï¼‰"""
        logger.info("ğŸ”„ å¼ºåˆ¶é‡æ–°åˆå§‹åŒ– GraphRAG...")
        self._pipeline = None
        self._config_hash = None
        self._initialize_pipeline(force=True)
    
    def is_ready(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å°±ç»ª"""
        try:
            pipeline = self.get_pipeline()
            return pipeline is not None
        except:
            return False
    
    def save_upload_file(self, upload_file: UploadFile) -> Path:
        """ä¿å­˜ä¸Šä¼ æ–‡ä»¶"""
        file_path = self.upload_dir / f"{uuid.uuid4()}_{upload_file.filename}"
        
        try:
            with file_path.open("wb") as buffer:
                shutil.copyfileobj(upload_file.file, buffer)
            return file_path
        finally:
            upload_file.file.close()
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.is_ready():
            return {
                'enabled': False,
                'total_documents': 0,
                'total_entities': 0,
                'total_relationships': 0,
                'total_communities': 0,
                'index_status': 'Not initialized'
            }
        
        try:
            pipeline = self.get_pipeline()
            total_communities = sum(len(comms) for comms in pipeline.communities.values())
            is_indexed = pipeline.community_summary_index is not None
            
            return {
                'enabled': True,
                'total_documents': len(pipeline.documents),
                'total_entities': len(pipeline.entities),
                'total_relationships': len(pipeline.relationships),
                'total_communities': total_communities,
                'index_status': 'Indexed' if is_indexed else 'Not indexed'
            }
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'enabled': False,
                'total_documents': 0,
                'total_entities': 0,
                'total_relationships': 0,
                'total_communities': 0,
                'index_status': f'Error: {str(e)}'
            }
    
    def save(self):
        """ä¿å­˜çŸ¥è¯†åº“"""
        try:
            pipeline = self.get_pipeline()
            pipeline.save("default")
            logger.info("âœ… GraphRAG çŸ¥è¯†åº“å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜çŸ¥è¯†åº“å¤±è´¥: {e}")
            raise


# ==================== Session ç®¡ç†å™¨ ====================

class SessionManager:
    def __init__(self):
        self.sessions = {}
        self.session_timestamps = {}
    def get_or_create_session(self, session_id=None):
        if session_id and session_id in self.sessions: return session_id, self.sessions[session_id]
        sid = str(uuid.uuid4())
        self.sessions[sid] = ConversationalAgent()
        return sid, self.sessions[sid]
    def clear_session(self, sid):
        if sid in self.sessions: self.sessions[sid].clear_history()
    def delete_session(self, sid):
        if sid in self.sessions: del self.sessions[sid]
    def cleanup_old_sessions(self, timeout): pass
    def get_session_count(self): return len(self.sessions)

def load_config_from_file(): return {}
def save_config_to_file(cfg): return {}


# ==================== å…¨å±€ç®¡ç†å™¨å®ä¾‹ ====================

session_manager = SessionManager()
graphrag_manager = GraphRAGManager()


# ==================== è¾…åŠ©å‡½æ•° ====================

def load_history_from_file() -> List[Dict[str, Any]]:
    """ä»æ–‡ä»¶åŠ è½½å†å²è®°å½•"""
    if HISTORY_FILE.exists():
        try:
            with HISTORY_FILE.open('r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    return data
                return []
        except Exception as e:
            logger.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
            return []
    return []


def load_config_from_file() -> Dict[str, Any]:
    """ä» JSON æ–‡ä»¶åŠ è½½é…ç½®"""
    if CONFIG_FILE.exists():
        try:
            with CONFIG_FILE.open('r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    return {
        "llm_config": {},
        "search_config": {},
        "firecrawl_config": {},
        "embedding_config": {}
    }


def save_config_to_file(new_flat_config: Dict[str, str]) -> Dict[str, Any]:
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    current_config = load_config_from_file()
    
    field_mapping = {
        'LLM_API_KEY': 'llm_config',
        'LLM_URL': 'llm_config',
        'LLM_MODEL': 'llm_config',
        'TAVILY_API_KEY': 'search_config',
        'FIRECRAWL_API_KEY': 'firecrawl_config',
        'FIRECRAWL_URL': 'firecrawl_config',
        'EMBEDDING_API_KEY': 'embedding_config',
        'EMBEDDING_URL': 'embedding_config',
        'EMBEDDING_MODEL': 'embedding_config'
    }
    
    for key, value in new_flat_config.items():
        if not value or ("..." in value and len(value) < 20):
            continue
        
        group = field_mapping.get(key)
        if group:
            if group not in current_config:
                current_config[group] = {}
            current_config[group][key] = value
    
    try:
        with CONFIG_FILE.open('w', encoding='utf-8') as f:
            json.dump(current_config, f, ensure_ascii=False, indent=4)
        logger.info(f"âœ… é…ç½®å·²ä¿å­˜åˆ°æ–‡ä»¶: {CONFIG_FILE}")
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        raise
    
    return current_config


async def rebuild_index_background():
    """åå°ä»»åŠ¡ï¼šé‡å»ºç´¢å¼•"""
    try:
        logger.info("ğŸ“Š å¼€å§‹é‡å»º GraphRAG ç´¢å¼•...")
        pipeline = graphrag_manager.get_pipeline()
        await pipeline.rebuild_index()
        graphrag_manager.save()
        logger.info("âœ… GraphRAG ç´¢å¼•é‡å»ºå®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ é‡å»ºç´¢å¼•å¤±è´¥: {e}", exc_info=True)



@router.post("/chat", response_model=ChatResponse, tags=["å¯¹è¯"])
async def chat(request: ChatRequest):
    """åŒæ­¥å¯¹è¯æ¥å£"""
    try:
        session_manager.cleanup_old_sessions(settings.SESSION_TIMEOUT)
        session_id, agent = session_manager.get_or_create_session(request.session_id)
        
        logger.info(f"[{session_id}] æ”¶åˆ°æ¶ˆæ¯: {request.message[:50]}...")
        
        response_content = await agent.chat(request.message)
        
        return ChatResponse(
            message=response_content,
            session_id=session_id,
            timestamp=datetime.now().isoformat()
        )
    
    except Exception as e:
        logger.error(f"å¯¹è¯å¤„ç†å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/history/saved", response_model=SavedHistoryListResponse, tags=["å¯¹è¯å†å²"])
async def get_saved_history_list():
    """è·å–æ‰€æœ‰å·²ä¿å­˜çš„ä¼šè¯å†å²åˆ—è¡¨"""
    try:
        # è°ƒç”¨åˆšåˆšä¿®æ”¹è¿‡çš„ list_sessions

        history_manager=ConversationHistoryManager()
        sessions = history_manager.list_sessions()
        
        return SavedHistoryListResponse(
            success=True,
            total=len(sessions),
            sessions=sessions
        )
    except Exception as e:
        logger.error(f"è·å–å†å²è®°å½•åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
@router.get("/history/{session_id}", response_model=HistoryResponse, tags=["å¯¹è¯"])
async def get_history(session_id: str):
    """è·å–å¯¹è¯å†å²"""
    if session_id not in session_manager.sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    agent = session_manager.sessions[session_id]
    
    return HistoryResponse(
        history=agent.get_history(),
        session_id=session_id
    )

@router.post("/clear/{session_id}", response_model=StatusResponse, tags=["å¯¹è¯"])
async def clear_history(session_id: str):
    """æ¸…ç©ºå¯¹è¯å†å²"""
    if session_id not in session_manager.sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session_manager.clear_session(session_id)
    
    return StatusResponse(
        status="ok",
        message="History cleared"
    )


@router.delete("/session/{session_id}", response_model=StatusResponse, tags=["å¯¹è¯"])
async def delete_session(session_id: str):
    """åˆ é™¤ Session"""
    if session_id not in session_manager.sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session_manager.delete_session(session_id)
    
    return StatusResponse(
        status="ok",
        message="Session deleted"
    )


# ==================== GraphRAG æ¥å£ ====================

@router.post("/graphrag/documents/upload", response_model=UploadResponse, tags=["GraphRAG"])
async def upload_document(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    title: Optional[str] = None,
    author: Optional[str] = None,
    category: Optional[str] = None,
    auto_rebuild: bool = True
):
    """ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
    
    allowed_extensions = {'.pdf', '.docx', '.doc', '.txt', '.md', '.markdown', '.csv'}
    file_extension = Path(file.filename).suffix.lower()
    
    if file_extension not in allowed_extensions:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}"
        )
    
    try:
        # ä¿å­˜æ–‡ä»¶
        file_path = graphrag_manager.save_upload_file(file)
        logger.info(f"ğŸ“„ æ–‡ä»¶å·²ä¿å­˜: {file_path}")
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            "title": title or file.filename,
            "author": author,
            "category": category,
            "original_filename": file.filename,
            "file_extension": file_extension,
            "uploaded_at": datetime.now().isoformat()
        }
        
        # â˜… ä½¿ç”¨ç»Ÿä¸€çš„ pipeline
        pipeline = graphrag_manager.get_pipeline()
        doc_uuid = await pipeline.add_document(str(file_path), metadata)
        doc_info = pipeline.documents[pipeline.uuid_to_docid[doc_uuid]]
        
        # åå°é‡å»ºç´¢å¼•
        if auto_rebuild:
            background_tasks.add_task(rebuild_index_background)
        
        return UploadResponse(
            success=True,
            message="æ–‡æ¡£ä¸Šä¼ æˆåŠŸ" + ("ï¼Œæ­£åœ¨åå°é‡å»ºç´¢å¼•" if auto_rebuild else ""),
            document_id=doc_uuid,
            document_name=file.filename,
            chunks_count=len(doc_info['chunks']),
            uploaded_at=doc_info['added_at']
        )
        
    except Exception as e:
        logger.error(f"âŒ ä¸Šä¼ æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
        if 'file_path' in locals() and file_path.exists():
            file_path.unlink()
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.get("/graphrag/documents", response_model=ListDocumentsResponse, tags=["GraphRAG"])
async def list_documents():
    """è·å–æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨"""
    try:
        # â˜… ä½¿ç”¨ç»Ÿä¸€çš„ pipeline
        pipeline = graphrag_manager.get_pipeline()
        docs =  pipeline.list_documents()
        
        documents = [
            DocumentInfo(
                document_id=doc['uuid'],
                name=doc['name'],
                path=doc['path'],
                chunks=doc['chunks'],
                uploaded_at=doc['added_at'],
                metadata=doc['metadata']
            )
            for doc in docs
        ]
        
        return ListDocumentsResponse(
            success=True,
            total=len(documents),
            documents=documents
        )
        
    except Exception as e:
        logger.error(f"âŒ è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.post("/graphrag/index/rebuild", tags=["GraphRAG"])
async def rebuild_index(background_tasks: BackgroundTasks):
    """æ‰‹åŠ¨è§¦å‘ç´¢å¼•é‡å»º"""
    stats = graphrag_manager.get_stats()
    if stats['total_documents'] == 0:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰æ–‡æ¡£å¯ä»¥ç´¢å¼•")
    
    try:
        background_tasks.add_task(rebuild_index_background)
        
        return {
            "success": True,
            "message": "ç´¢å¼•é‡å»ºä»»åŠ¡å·²æ·»åŠ åˆ°åå°é˜Ÿåˆ—",
            "total_documents": stats['total_documents']
        }
        
    except Exception as e:
        logger.error(f"âŒ è§¦å‘ç´¢å¼•é‡å»ºå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è§¦å‘ç´¢å¼•é‡å»ºå¤±è´¥: {str(e)}")


@router.get("/graphrag/index/status", response_model=IndexStatusResponse, tags=["GraphRAG"])
async def get_index_status():
    """è·å–ç´¢å¼•çŠ¶æ€"""
    try:
        stats = graphrag_manager.get_stats()
        is_indexed = stats['index_status'] == 'Indexed'
        
        return IndexStatusResponse(
            success=True,
            is_indexed=is_indexed,
            total_documents=stats['total_documents'],
            total_entities=stats['total_entities'],
            total_relationships=stats['total_relationships'],
            total_communities=stats['total_communities'],
            message=stats['index_status']
        )
        
    except Exception as e:
        logger.error(f"âŒ è·å–ç´¢å¼•çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–ç´¢å¼•çŠ¶æ€å¤±è´¥: {str(e)}")


@router.post("/graphrag/query", response_model=QueryResponse, tags=["GraphRAG"])
async def query_knowledge_base(request: QueryRequest):
    """æŸ¥è¯¢çŸ¥è¯†åº“"""
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="é—®é¢˜ä¸èƒ½ä¸ºç©º")
    
    try:
        start_time = datetime.now()
        
        # â˜… ä½¿ç”¨ç»Ÿä¸€çš„ pipeline
        pipeline = graphrag_manager.get_pipeline()
        answer = await pipeline.global_query(
            request.question,
            top_k_communities=request.top_k_communities
        )
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        logger.info(f"âœ… æŸ¥è¯¢å®Œæˆ: {request.question[:50]}... (è€—æ—¶ {processing_time:.2f}s)")
        
        return QueryResponse(
            success=True,
            question=request.question,
            answer=answer,
            processing_time=processing_time
        )
        
    except RuntimeError as e:
        if "ç´¢å¼•æœªæ„å»º" in str(e):
            raise HTTPException(
                status_code=400,
                detail="ç´¢å¼•æœªæ„å»ºï¼Œè¯·å…ˆä¸Šä¼ æ–‡æ¡£å¹¶ç­‰å¾…ç´¢å¼•æ„å»ºå®Œæˆ"
            )
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


# ==================== é…ç½®ç®¡ç†æ¥å£ ====================

@router.get("/config", response_model=ConfigResponse, tags=["é…ç½®ç®¡ç†"])
async def get_config():
    """è·å–å½“å‰é…ç½®"""
    try:
        config_data = load_config_from_file()
        
        # æ·±æ‹·è´å¹¶è„±æ•
        safe_config = json.loads(json.dumps(config_data))
        
        for group, items in safe_config.items():
            if isinstance(items, dict):
                for key, value in items.items():
                    if value and isinstance(value, str) and 'KEY' in key.upper() and len(value) > 8:
                        items[key] = f"{value[:4]}...{value[-4:]}"
        
        return ConfigResponse(
            success=True,
            message="é…ç½®è·å–æˆåŠŸ",
            config=safe_config
        )
        
    except Exception as e:
        logger.error(f"âŒ è·å–é…ç½®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–é…ç½®å¤±è´¥: {str(e)}")


@router.post("/config", response_model=ConfigResponse, tags=["é…ç½®ç®¡ç†"])
async def update_config(config: Dict[str, str]):
    """æ›´æ–°é…ç½®"""
    try:
        # ä¿å­˜é…ç½®
        updated_nested_config = save_config_to_file(config)
        
        # æ›´æ–° settings
        flat_settings = {}
        for group in updated_nested_config.values():
            if isinstance(group, dict):
                flat_settings.update(group)
        settings.update(**flat_settings)
        
        # â˜…â˜…â˜… å…³é”®ï¼šå¼ºåˆ¶é‡æ–°åˆå§‹åŒ– GraphRAG â˜…â˜…â˜…
        try:
            graphrag_manager.force_reinitialize()
            logger.info("âœ… GraphRAG å·²ä½¿ç”¨æ–°é…ç½®é‡æ–°åˆå§‹åŒ–")
        except Exception as e:
            logger.warning(f"âš ï¸ GraphRAG é‡æ–°åˆå§‹åŒ–å¤±è´¥ï¼ˆå¯èƒ½é…ç½®ä¸å®Œæ•´ï¼‰: {e}")
        
        logger.info(f"âœ… é…ç½®å·²æ›´æ–°å¹¶åº”ç”¨")
        
        return ConfigResponse(
            success=True,
            message="é…ç½®ä¿å­˜æˆåŠŸ",
            config=None
        )
        
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°é…ç½®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°é…ç½®å¤±è´¥: {str(e)}")


# ==================== æœåŠ¡ä¿¡æ¯æ¥å£ ====================

@router.get("/info", tags=["æœåŠ¡ä¿¡æ¯"])
async def get_info():
    """è·å–æœåŠ¡ä¿¡æ¯"""
    graphrag_stats = graphrag_manager.get_stats()
    
    return {
        "service": settings.APP_NAME,
        "version": settings.APP_VERSION,
        "features": {
            "streaming": True,
            "graphrag": graphrag_stats['enabled'],
            "config_management": True
        },
        "endpoints": {
            "http": {
                "chat": "/api/chat",
                "config_get": "/api/config",
                "config_update": "/api/config"
            }
        },
        "graphrag_status": graphrag_stats
    }


@router.get("/stats", tags=["æœåŠ¡ä¿¡æ¯"])
async def get_stats():
    """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    graphrag_stats = graphrag_manager.get_stats()
    
    return {
        "active_sessions": session_manager.get_session_count(),
        "graphrag": graphrag_stats,
        "config_loaded": CONFIG_FILE.exists(),
        "timestamp": datetime.now().isoformat()
    }

@router.get("/person_like", tags=["ä¸ªäººåå¥½æŒ–æ˜"])
async def get_person_like():
    mining_enginer=UserPreferenceMining()
    return mining_enginer.get_frontend_format()
