import logging
import os
from pathlib import Path
from typing import List, Dict, Optional, Any
from deepagents import create_deep_agent
from deepagents.backends.filesystem import FilesystemBackend
from langgraph.checkpoint.memory import MemorySaver
from langchain.chat_models import init_chat_model
from langchain_community.tools import ShellTool
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from src.services.base import BaseConfigurableService
from src.services.person_like_service import UserPreferenceMining
from src.workflow.callbacks import StatusCallback

logger = logging.getLogger(__name__)

class ConversationalAgent(BaseConfigurableService):
    """
    åŸºäº DeepAgents é‡æ„çš„æ™ºèƒ½ Agent
    """    
    def __init__(self, status_callback: Optional[StatusCallback] = None):
        super().__init__()
        
        self.status_callback = status_callback
        self.workspace = self.settings.SKILL_DIR
        # 1.ç”¨æˆ·ç”»åƒ
        self.user_profile_data = UserPreferenceMining().get_frontend_format()
        self.user_summary = self.user_profile_data.get("summary", "No specific preference.")
        # 2. åŸºç¡€è®¾æ–½å·¥å…·
        self.exec_tool = ShellTool()
        self.exec_tool.description = (
            "Execute shell commands. Use this ONLY when a Skill documentation "
            "instructs you to run a specific python script."
        )

    def build_instance(self):
        """
        æ„å»º Deep Agent å®ä¾‹
        """
        # 1. åˆå§‹åŒ–æ¨¡å‹
        logger.info(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹: {self.settings.LLM_MODEL} æ„å»º Agent")
        model = init_chat_model(
            model=self.settings.LLM_MODEL,
            model_provider="openai",
            api_key=self.settings.LLM_API_KEY,
            base_url=self.settings.LLM_URL
        )
        self.exec_tool = ShellTool()
        self.exec_tool.name = "shell"
        self.exec_tool.description = (
            f"Run python scripts. ALL commands must be relative to: {self.workspace}. "
            "DO NOT use absolute paths. DO NOT use 'cd' or 'ls'."
        )
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªç²¾ç¡®æ‰§è¡Œçš„æ™ºèƒ½ä½“ï¼Œéœ€è¦åˆ¤æ–­æ˜¯å¦è¿›è¡Œå·¥å…·çš„è°ƒç”¨ï¼Œå¦‚æœæ˜¯é—²èŠï¼Œåˆ™ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¦‚æœæ˜¯éœ€è¦æä¾›çš„æŠ€èƒ½ï¼Œéœ€è¦æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æ¥å¯»æ‰¾ä¸€ä¸ªåˆé€‚çš„æŠ€èƒ½ï¼Œå¹¶æ‰§è¡ŒæŠ€èƒ½ã€‚ 
**æŠ€èƒ½ç›®å½•**ï¼šä½ å¯ä»¥ä½¿ç”¨çš„æŠ€èƒ½ç›®å½•æ˜¯ {self.workspace}ï¼Œä¸å…è®¸è®¿é—®å…¶ä»–ç›®å½•ï¼Œè‡ªè¡Œè¿›è¡Œå·¥å…·çš„è°ƒç”¨ï¼›ä¸å…è®¸è‡ªè¡Œè¿›è¡Œæ’°å†™æ–‡ä»¶è¿›è¡Œæ‰§è¡Œã€‚
**ç”¨æˆ·**: 
# ğŸ‘¤ ç”¨æˆ·ä¸Šä¸‹æ–‡
{self.user_summary}
"""
        
        return create_deep_agent(
            model=model,
            backend=FilesystemBackend(root_dir=str(self.settings.PROJECT_ROOT)),
            skills=[str(self.workspace)], 
            tools=[self.exec_tool],
            checkpointer=MemorySaver(),
            system_prompt=system_prompt
        )
    
    async def chat(self, user_input: str, thread_id: str = "default_thread") -> str:
        """
        å¤„ç†å¯¹è¯ï¼Œå…¼å®¹æ—§æ¥å£ï¼Œå¹¶é€‚é… StatusCallback
        """
        config = {"configurable": {"thread_id": thread_id}}
        agent_instance=self.get_instance()
        
        # è§¦å‘å›è°ƒï¼šå¼€å§‹
        if self.status_callback:
            # æ¨¡æ‹Ÿæ—§ç‰ˆå›è°ƒç»“æ„
            await self.status_callback.on_agent_start({"input": user_input})
        final_response = ""
        try:
            logger.info(f"å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input[:50]}...")
            
            # ä½¿ç”¨ stream æ¥è·å–ä¸­é—´æ­¥éª¤ï¼Œä»¥è§¦å‘å›è°ƒ
            async for event in agent_instance.astream(
                {"messages": [HumanMessage(content=user_input)]},
                config=config,
                stream_mode="values"
            ):
                if "messages" in event and len(event["messages"]) > 0:
                    last_msg = event["messages"][-1]
                    
                    if isinstance(last_msg, AIMessage) and last_msg.tool_calls:
                        for tool_call in last_msg.tool_calls:
                            action_name = tool_call['name']
                            args = tool_call['args']
                            logger.info(f"Agent æ­£åœ¨è°ƒç”¨å·¥å…·: {action_name}")
                            
                            if self.status_callback:
                                # æ¨¡æ‹Ÿå‘é€çŠ¶æ€æ›´æ–°
                                await self.status_callback.on_tool_start(
                                    {"name": action_name, "args": args}
                                )
                    
                    elif isinstance(last_msg, ToolMessage):
                        logger.info(f"å·¥å…·æ‰§è¡Œå®Œæˆ: {last_msg.name}")
                        if self.status_callback:
                            await self.status_callback.on_tool_end(
                                {"output": str(last_msg.content)[:200] + "..."}
                            )               
                    elif isinstance(last_msg, AIMessage) and not last_msg.tool_calls:
                        final_response = last_msg.content
            # è§¦å‘å›è°ƒï¼šç»“æŸ
            if self.status_callback:
                await self.status_callback.on_agent_finish({"output": final_response})       
            logger.info(f"ç”Ÿæˆå›ç­”: {final_response}...")
            return final_response
        except Exception as e:
            logger.error(f"å¤„ç†å¯¹è¯å¤±è´¥: {e}", exc_info=True)

            return f"ç³»ç»Ÿé”™è¯¯: {str(e)}"