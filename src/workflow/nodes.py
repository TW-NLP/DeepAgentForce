"""
å·¥ä½œæµèŠ‚ç‚¹æ¨¡å—
å®šä¹‰æ‰€æœ‰å·¥ä½œæµèŠ‚ç‚¹å‡½æ•°
"""

import json
import logging
from typing import Dict, Any, Optional
from langchain.messages import HumanMessage, AIMessage

from config.settings import settings
from config.prompts import prompts
from src.services.llm_service import get_llm_service
from src.services.search_service import get_search_service
from src.services.rag_service import get_rag_service
from src.workflow.callbacks import EventType, StepEvent

logger = logging.getLogger(__name__)


# ç±»å‹å®šä¹‰
AgentState = Dict[str, Any]


async def plan_node(state: AgentState) -> Dict[str, Any]:
    """
    æ™ºèƒ½ä»»åŠ¡è§„åˆ’èŠ‚ç‚¹ - åˆ†æä»»åŠ¡å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    callback = state.get("status_callback")
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="planning",
            title="ğŸ¤” åˆ†æä»»åŠ¡",
            description="æ­£åœ¨åˆ¶å®šæ‰§è¡Œè®¡åˆ’..."
        ))
    
    last_message = state["messages"][-1]
    
    if isinstance(last_message, HumanMessage):
        query = last_message.content
        conversation_history = state.get("conversation_history", [])
        user_profile = state.get("user_profile", "æš‚æ— ç”¨æˆ·åå¥½ä¿¡æ¯")
        
        # æ ¼å¼åŒ–å¯¹è¯å†å²
        history_context = prompts.format_history_context(
            conversation_history,
            limit=settings.CONVERSATION_HISTORY_LIMIT
        )
        
        # æ„å»ºè§„åˆ’æç¤ºè¯
        plan_prompt = prompts.TASK_PLANNING.format(
            history_context=history_context,
            user_profile=user_profile,
            query=query
        )
        
        # è°ƒç”¨ LLM ç”Ÿæˆè®¡åˆ’
        llm_service = get_llm_service()
        try:
            content, _ = await llm_service.generate(
                prompt=plan_prompt,
                streaming=False,
                use_planner_config=True
            )
            
            # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—
            content = content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            
            plan = json.loads(content.strip())
            
            if callback:
                steps_desc = "\n".join([
                    f"  {i+1}. {s['action']}: {s['reason']}"
                    for i, s in enumerate(plan.get('steps', []))
                ])
                await callback.emit(EventType.STEP, StepEvent.create(
                    step="plan_decided",
                    title="âœ“ è§„åˆ’å®Œæˆ",
                    description=f"ä»»åŠ¡ç±»å‹: {plan.get('task_type', 'unknown')}\næ‰§è¡Œæ­¥éª¤:\n{steps_desc}"
                ))
            
            # åˆ¤æ–­ä¸‹ä¸€æ­¥
            if plan.get("task_type") == "composite":
                next_step = "execute_plan"
            elif len(plan.get("steps", [])) == 1:
                # å•æ­¥ä»»åŠ¡ç›´æ¥è·¯ç”±
                single_step = plan["steps"][0]["action"]
                next_step = single_step
            else:
                next_step = "execute_plan"
            
            logger.info(f"[è§„åˆ’] ä»»åŠ¡ç±»å‹: {plan.get('task_type')}, ä¸‹ä¸€æ­¥: {next_step}")
            
            return {
                "search_query": query,
                "execution_plan": plan,
                "next_step": next_step
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"è§„åˆ’è§£æå¤±è´¥: {e}, å“åº”: {content}")
            # é™çº§ä¸ºèŠå¤©æ¨¡å¼
            return {
                "search_query": query,
                "next_step": "chat"
            }
        except Exception as e:
            logger.error(f"è§„åˆ’å¤±è´¥: {e}")
            return {
                "search_query": query,
                "next_step": "chat"
            }
    
    return {"next_step": "end"}


async def execute_plan_node(state: AgentState) -> Dict[str, Any]:
    """
    æ‰§è¡Œå¤šæ­¥éª¤è®¡åˆ’èŠ‚ç‚¹
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    callback = state.get("status_callback")
    plan = state.get("execution_plan", {})
    
    if not plan or "steps" not in plan:
        return {"next_step": "chat"}
    
    steps = plan["steps"]
    logger.info(f'æ­£åœ¨æ‰§è¡Œå¤åˆä»»åŠ¡ï¼Œæ­¥éª¤: {[s["action"] for s in steps]}')
    
    collected_data = {
        "web_results": [],
        "doc_results": []
    }
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="execute_start",
            title="ğŸš€ å¼€å§‹æ‰§è¡Œè®¡åˆ’",
            description=f"å…± {len(steps)} ä¸ªæ­¥éª¤"
        ))
    
    # æ‰§è¡Œæ¯ä¸ªæ­¥éª¤
    for i, step in enumerate(steps, 1):
        action = step["action"]
        query = step.get("query", state["search_query"])
        
        if callback:
            await callback.emit(EventType.STEP, StepEvent.create(
                step=f"execute_{i}",
                title=f"ğŸ“‹ æ‰§è¡Œæ­¥éª¤ {i}/{len(steps)}",
                description=f"{step['reason']}: {query}"
            ))
        
        if action == "web_search":
            # æ‰§è¡Œç½‘ç»œæœç´¢
            try:
                search_service = get_search_service()
                result = await search_service.search_and_crawl(
                    query=query,
                    num_urls=settings.MAX_URLS_TO_CRAWL
                )
                
                collected_data["web_results"].append({
                    "query": query,
                    "reason": step["reason"],
                    "content": result.get("crawled_contents", [])
                })
                
                if callback:
                    await callback.emit(EventType.STEP, StepEvent.create(
                        step=f"web_search_done_{i}",
                        title=f"âœ“ ç½‘ç»œæœç´¢å®Œæˆ",
                        description=f"è·å–äº† {len(result.get('crawled_contents', []))} ä¸ªç½‘é¡µå†…å®¹"
                    ))
            except Exception as e:
                logger.error(f"ç½‘ç»œæœç´¢å¤±è´¥: {e}")
                if callback:
                    await callback.emit(EventType.ERROR, {
                        "step": f"web_search_error_{i}",
                        "message": f"æœç´¢å¤±è´¥: {str(e)}"
                    })
        
        elif action == "doc_search":
            # æ‰§è¡Œæ–‡æ¡£æœç´¢
            try:
                rag_service = get_rag_service()
                result = await rag_service.search_and_format(
                    query=query
                )
                logger.info(f"[æ–‡æ¡£æœç´¢] æŸ¥è¯¢: {query}, å“åº”: {result}")
                
                collected_data["doc_results"].append({
                    "query": query,
                    "reason": step["reason"],
                    "content": result.get("formatted_content", "")
                })
                
                if callback:
                    await callback.emit(EventType.STEP, StepEvent.create(
                        step=f"doc_search_done_{i}",
                        title=f"âœ“ æ–‡æ¡£æœç´¢å®Œæˆ",
                        description=f"æ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£"
                    ))
            except Exception as e:
                logger.error(f"æ–‡æ¡£æœç´¢å¤±è´¥: {e}")
                if callback:
                    await callback.emit(EventType.ERROR, {
                        "step": f"doc_search_error_{i}",
                        "message": f"æ–‡æ¡£æ£€ç´¢å¤±è´¥: {str(e)}"
                    })
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="execute_complete",
            title="âœ“ è®¡åˆ’æ‰§è¡Œå®Œæˆ",
            description=f"å·²å®Œæˆ {len(steps)} ä¸ªæ­¥éª¤çš„æ•°æ®æ”¶é›†"
        ))
    
    return {
        "collected_data": collected_data,
        "messages": [AIMessage(content=f"å·²å®Œæˆ {len(steps)} ä¸ªæ­¥éª¤çš„æ•°æ®æ”¶é›†")],
        "next_step": "synthesize" if plan.get("final_action") == "synthesize" else "end"
    }


async def synthesize_node(state: AgentState) -> Dict[str, Any]:
    """
    ç»¼åˆåˆ†æèŠ‚ç‚¹ - æ•´åˆå¤šæºæ•°æ®ç”Ÿæˆå»ºè®®
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    logger.info(f"è¿›å…¥ç»¼åˆåˆ†æèŠ‚ç‚¹, é—®é¢˜: {state['search_query']}")
    callback = state.get("status_callback")
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="synthesizing",
            title="ğŸ§  ç»¼åˆåˆ†æ",
            description="æ­£åœ¨æ•´åˆä¿¡æ¯å¹¶ç”Ÿæˆå»ºè®®..."
        ))
    
    query = state["search_query"]
    collected_data = state.get("collected_data", {})
    conversation_history = state.get("conversation_history", [])
    
    # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
    history_context = prompts.format_history_context(conversation_history)

    logger.info(f"ç»¼åˆåˆ†æèŠ‚ç‚¹, collected_data: {collected_data}")

    web_context = prompts.format_web_context(collected_data.get("web_results", []))
    doc_context = prompts.format_doc_context(collected_data.get("doc_results", []))
    
    # æ„å»ºç»¼åˆæç¤ºè¯
    prompt = prompts.SYNTHESIS.format(
        history_context=history_context,
        query=query,
        web_context=web_context,
        doc_context=doc_context
    )
    
    # æµå¼ç”Ÿæˆ
    llm_service = get_llm_service()
    
    async def status_callback_wrapper(event_type: str, data: Dict[str, Any]):
        if callback:
            await callback.emit(event_type, data)
    
    content, _ = await llm_service.generate(
        prompt=prompt,
        streaming=True,
        callback=status_callback_wrapper
    )
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="synthesize_complete",
            title="âœ“ åˆ†æå®Œæˆ",
            description="å·²ç”Ÿæˆç»¼åˆå»ºè®®"
        ))
    
    return {
        "final_summary": content,
        "messages": [AIMessage(content=content)],
        "next_step": "end"
    }


async def web_search_node(state: AgentState) -> Dict[str, Any]:
    """
    ç½‘ç»œæœç´¢èŠ‚ç‚¹
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    callback = state.get("status_callback")
    query = state["search_query"]
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="web_search",
            title="ğŸ” ç½‘ç»œæœç´¢",
            description=f"æ­£åœ¨æœç´¢: {query}"
        ))
    
    # è°ƒç”¨æœç´¢æœåŠ¡
    search_service = get_search_service()
    result = await search_service.search_and_crawl(query)
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="search_complete",
            title="âœ“ æœç´¢å®Œæˆ",
            description=f"æ‰¾åˆ° {len(result.get('crawled_contents', []))} ä¸ªç›¸å…³ç»“æœ"
        ))
    
    return {
        "search_results": result.get("search_results", {}),
        "crawled_contents": result.get("crawled_contents", []),
        "messages": [AIMessage(content=f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(result.get('crawled_contents', []))} ä¸ªç›¸å…³ç½‘é¡µ")],
        "next_step": "summarize"
    }


async def summarize_node(state: AgentState) -> Dict[str, Any]:
    """
    æ±‡æ€»èŠ‚ç‚¹ï¼šç”Ÿæˆç½‘ç»œæœç´¢ç»“æœçš„æ‘˜è¦
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    callback = state.get("status_callback")
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="summarizing",
            title="ğŸ“ ç”Ÿæˆå›ç­”",
            description="æ­£åœ¨æ•´åˆä¿¡æ¯å¹¶ç”Ÿæˆå›ç­”..."
        ))
    
    crawl_flag = state.get("crawled_flag")
    crawl_content=state.get("crawled_contents", [])

    search_res=state.get("search_results", [])
    # è‹¥æ²¡æœ‰é…ç½® crawl å°±ç”¨searchçš„å†…å®¹
    search_summary=prompts.format_crawled_content(crawl_content) if crawl_flag else prompts.format_search_content(search_res)
    query = state["search_query"]
    conversation_history = state.get("conversation_history", [])
    
    # æ ¼å¼åŒ–å†…å®¹
    history_context = prompts.format_history_context(conversation_history)
    # content_text = prompts.format_crawled_content(search_summary)
    
    # æ„å»ºæç¤ºè¯
    prompt = prompts.WEB_SEARCH_SUMMARY.format(
        history_context=history_context,
        query=query,
        content_text=search_summary
    )
    
    # æµå¼ç”Ÿæˆ
    llm_service = get_llm_service()
    
    async def status_callback_wrapper(event_type: str, data: Dict[str, Any]):
        if callback:
            await callback.emit(event_type, data)
    
    content, _ = await llm_service.generate(
        prompt=prompt,
        streaming=True,
        callback=status_callback_wrapper
    )
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="summarize_complete",
            title="âœ“ å›ç­”å®Œæˆ",
            description="å·²ç”Ÿæˆå®Œæ•´å›ç­”"
        ))
    
    return {
        "final_summary": content,
        "messages": [AIMessage(content=content)],
        "next_step": "end"
    }


async def doc_search_node(state: AgentState) -> Dict[str, Any]:
    """
    æ–‡æ¡£æœç´¢èŠ‚ç‚¹
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    callback = state.get("status_callback")
    query = state["search_query"]
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="docqa_search",
            title="ğŸ“š æœç´¢æ–‡æ¡£åº“",
            description=f"æ­£åœ¨æ–‡æ¡£åº“ä¸­æœç´¢: {query}"
        ))
    
    # è°ƒç”¨ RAG æœåŠ¡
    rag_service = get_rag_service()
    try:
        result = await rag_service.search_and_format(query)
        
        if callback:
            await callback.emit(EventType.STEP, StepEvent.create(
                step="docqa_found",
                title="âœ“ æ–‡æ¡£æ£€ç´¢å®Œæˆ",
                description=result.get("description", "å·²å®Œæˆæ–‡æ¡£å†…å®¹æ£€ç´¢") 
            ))
        
        return {
            "docqa_content": result.get("formatted_content", ""),
            "messages": [AIMessage(content="å·²ä»æ–‡æ¡£åº“æ£€ç´¢åˆ°ç›¸å…³å†…å®¹")],
            "description": result.get("description", ""),
            "next_step": "llm_node"
        }
    except Exception as e:
        logger.error(f"æ–‡æ¡£æ£€ç´¢å¤±è´¥: {e}")
        if callback:
            await callback.emit(EventType.ERROR, {
                "step": "docqa_error",
                "message": f"æ–‡æ¡£æ£€ç´¢é”™è¯¯: {str(e)}"
            })
        return {
            "docqa_content": "æ–‡æ¡£æ£€ç´¢å¤±è´¥",
            "messages": [AIMessage(content="æ–‡æ¡£æ£€ç´¢å¤±è´¥")],
            "next_step": "llm_node"
        }


async def llm_node(state: AgentState) -> Dict[str, Any]:
    """
    æ–‡æ¡£é—®ç­”çš„æ±‡æ€»å›ç­”èŠ‚ç‚¹
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    callback = state.get("status_callback")
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="generating",
            title="âœï¸ ç”Ÿæˆå›ç­”",
            description="åŸºäºæ–‡æ¡£å†…å®¹ç”Ÿæˆå›ç­”..."
        ))
    
    docqa_content = state.get("docqa_content", "")
    query = state["search_query"]
    conversation_history = state.get("conversation_history", [])
    
    # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
    history_context = prompts.format_history_context(conversation_history)
    
    # æ„å»ºæç¤ºè¯
    prompt = prompts.DOC_QA.format(
        history_context=history_context,
        query=query,
        docqa_content=docqa_content
    )
    
    # æµå¼ç”Ÿæˆ
    llm_service = get_llm_service()
    
    async def status_callback_wrapper(event_type: str, data: Dict[str, Any]):
        if callback:
            await callback.emit(event_type, data)
    
    content, _ = await llm_service.generate(
        prompt=prompt,
        streaming=True,
        callback=status_callback_wrapper
    )
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="generate_complete",
            title="âœ“ å›ç­”å®Œæˆ",
            description="å·²åŸºäºæ–‡æ¡£ç”Ÿæˆå®Œæ•´å›ç­”"
        ))
    
    return {
        "final_summary": content,
        "messages": [AIMessage(content=content)],
        "next_step": "end"
    }


async def chat_node(state: AgentState) -> Dict[str, Any]:
    """
    èŠå¤©å¯¹è¯èŠ‚ç‚¹
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    callback = state.get("status_callback")
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="chatting",
            title="ğŸ’¬ å¯¹è¯ä¸­",
            description="æ­£åœ¨ç”Ÿæˆå›å¤..."
        ))
    
    query = state["search_query"]
    conversation_history = [{'role':"system","content":"ç”¨æˆ·åå¥½ï¼š"+state.get('user_profile') if state.get('user_profile') else "ç”¨æˆ·æ— ä»»ä½•åå¥½ æ­£å¸¸å›ç­”"}]+state.get("conversation_history", [])
    
    # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
    history_context = prompts.format_history_context(conversation_history)
    
    # æ„å»ºæç¤ºè¯
    prompt = prompts.CHAT.format(
        history_context=history_context,
        query=query
    )
    
    # æµå¼ç”Ÿæˆ
    llm_service = get_llm_service()
    
    async def status_callback_wrapper(event_type: str, data: Dict[str, Any]):
        if callback:
            await callback.emit(event_type, data)
    
    content, _ = await llm_service.generate(
        prompt=prompt,
        streaming=True,
        callback=status_callback_wrapper
    )
    
    if callback:
        await callback.emit(EventType.STEP, StepEvent.create(
            step="chat_complete",
            title="âœ“ å›å¤å®Œæˆ",
            description="å·²ç”Ÿæˆå›å¤"
        ))
    
    return {
        "final_summary": content,
        "messages": [AIMessage(content=content)],
        "next_step": "end"
    }